report:
  path: './results/linearPPO'

trainer:
  episodes: 10
  maxEpisodeLenght: 1000
  evalFreq: 5
  plot: True
  plotAction: True


agent:
  name: 'ppo'
  h: 1
  discount: 0.7
  a_layers: [3, 64, 64, 1]
  a_activation: ['tahn', 'tahn', 'identity']
  a_lr: 0.0001
  c_layers: [4, 64, 64, 1]
  c_activation: ['tahn', 'tahn', 'invRelu']
  c_lr: 0.01
  tau: 0.001
  weightDecay: 0.001
  batchSize: 512
  update_freq: 2 
  bufferSize: 10000
  clip: 0.2
  klCost: 0.001

env:
  name: 'linear-with-ref-v0'
  args:
    horizon: 2
    deltaActionCost: 0.001
