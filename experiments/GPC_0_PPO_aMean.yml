report:
  path: './results/GPC_0_PPO_aMean'

trainer:
  episodes: 2000 
  maxEpisodeLenght: 1000
  evalFreq: 10 
  plot: False
  plotAction: True


agent:
  name: 'nc-ppo'
  h: 3
  discount: 0.7

  a_layers: [6, 400, 300, 1]
  a_activation: ['relu', 'relu', 'identity']
  a_layerOptions: [{}, {}, {'bias': 20.0}]
  a_inCenter: [209.5, 11.0, 209.5, 209.5, 209.5, 209.5]
  a_lr: 0.0003
  
  model: 'GP'
  baseline: 'meanRewards'
  # c_layers: [6, 400, 300, 1]
  # c_activation: ['relu', 'relu', 'invRelu']
  # c_inCenter: [209.0, 11.0, 209.0, 209.0, 209.0, 209.0]
  # c_lr: 0.005
  tau: 0.001
  weightDecay: 0.000
  batchSize: 32
  update_freq: 2 
  bufferSize: 10000
  explorationNoise: 10.0 
  clip: 0.1
  klCost: 0.01

env:
  name: 'clutch-v0'
  args:
    horizon: 6
    deltaActionCost: 0.000
    rewardScaling: 1.0
