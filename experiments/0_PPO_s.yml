report:
  path: './results/0_PPO_s_h3'

trainer:
  episodes: 5000
  maxEpisodeLenght: 1000
  evalFreq: 50 
  plot: False
  plotAction: True


agent:
  name: 'ppo'
  h: 3
  discount: 0.7

  a_layers: [5, 64, 64, 1]
  a_activation: ['relu', 'relu', 'identity']
  a_layerOptions: [{}, {}, {'bias': 20.0}]
  a_lr: 0.0003
  c_layers: [5, 64, 64, 1]
  c_activation: ['relu', 'relu', 'invRelu']
  c_lr: 0.005
  tau: 0.001
  weightDecay: 0.000
  batchSize: 512
  update_freq: 2 
  bufferSize: 10000
  explorationNoise: 10.0 
  clip: 0.1
  klCost: 0.001

env:
  name: 'clutch-v0'
  args:
    horizon: 5
    deltaActionCost: 0.005
    rewardScaling: 1.0
