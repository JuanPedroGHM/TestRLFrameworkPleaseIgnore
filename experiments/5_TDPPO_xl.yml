report:
  path: './results/5_TDPPO_xl_h3'

trainer:
  episodes: 5000 
  maxEpisodeLenght: 1000
  evalFreq: 10
  plot: False
  plotAction: True


agent:
  name: 'tdppo'
  h: 3
  discount: 0.7

  a_layers: [4, 400, 400, 300, 1]
  a_activation: ['relu', 'relu', 'relu', 'identity']
  a_layerOptions: [{}, {}, {}, {'bias': 20.0}]
  a_lr: 0.0003
  c_layers: [4, 400, 400, 300, 1]
  c_activation: ['relu', 'relu', 'relu', 'invRelu']
  c_lr: 0.005
  tau: 0.005
  weightDecay: 0.000
  batchSize: 512
  update_freq: 2 
  bufferSize: 10000
  explorationNoise: 10.0 
  clip: 0.2
  klCost: 0.01

env:
  name: 'clutch-v0'
  args:
    horizon: 5
    deltaActionCost: 0.005
    rewardScaling: 1.0
