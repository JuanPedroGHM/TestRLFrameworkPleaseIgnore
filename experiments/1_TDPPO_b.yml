report:
  path: './results/1_TDPPO_b'

trainer:
  episodes: 2000 
  maxEpisodeLenght: 1000
  evalFreq: 10
  plot: False
  plotAction: True


agent:
  name: 'tdppo'
  h: 1
  discount: 0.7

  a_layers: [3, 400, 300, 1]
  a_activation: ['relu', 'relu', 'identity']
  a_layerOptions: [{}, {}, {'bias': 20.0}]
  a_inCenter: [0.0, 0.0, 11.0]
  a_lr: 0.0003
  c_layers: [3, 400, 300, 1]
  c_activation: ['relu', 'relu', 'invRelu']
  c_inCenter: [0.0, 0.0, 11.0]
  c_lr: 0.005
  tau: 0.001
  weightDecay: 0.000
  batchSize: 32
  update_freq: 2 
  bufferSize: 10000
  explorationNoise: 10.0 
  clip: 0.1
  klCost: 0.01

env:
  name: 'clutch-v0'
  args:
    horizon: 5
    deltaActionCost: 0.000
    rewardScaling: 1.0
